{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kf8xpaumQHlL",
        "outputId": "754de828-3014-488c-f370-ae5e780a5853"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.1-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.1 dill-0.3.8 fsspec-2025.3.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.1)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install scikit-learn\n",
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# upload personal kaggle.json file, get dataset from kaggle\n",
        "# dataset link: https://www.kaggle.com/datasets/usharengaraju/dynamically-generated-hate-speech-dataset\n",
        "from google.colab import files\n",
        "files.upload()  # Upload kaggle.json file\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download dataset\n",
        "!kaggle datasets download -d usharengaraju/dynamically-generated-hate-speech-dataset\n",
        "!unzip dynamically-generated-hate-speech-dataset.zip -d hate_speech_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "8DrARqCBQVSF",
        "outputId": "07bc0376-d1e7-475f-8a1f-f4e0e9f4f70a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b426d088-f79a-409f-a377-e74467d27ad8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b426d088-f79a-409f-a377-e74467d27ad8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Dataset URL: https://www.kaggle.com/datasets/usharengaraju/dynamically-generated-hate-speech-dataset\n",
            "License(s): other\n",
            "Archive:  dynamically-generated-hate-speech-dataset.zip\n",
            "  inflating: hate_speech_data/2020-12-31-DynamicallyGeneratedHateDataset-entries-v0.1.csv  \n",
            "  inflating: hate_speech_data/2020-12-31-DynamicallyGeneratedHateDataset-targets-v0.1.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data processing to generate intersectional labels\n",
        "# credit: Andy Liang\n",
        "\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "df1 = pd.read_csv('hate_speech_data/2020-12-31-DynamicallyGeneratedHateDataset-entries-v0.1.csv')\n",
        "df2 = pd.read_csv('hate_speech_data/2020-12-31-DynamicallyGeneratedHateDataset-targets-v0.1.csv')\n",
        "\n",
        "df1['id'] = df1['id'].astype(str).str.strip()\n",
        "df2['id'] = df2['id'].astype(str).str.strip()\n",
        "\n",
        "target_columns = df2.columns.drop(['id'])\n",
        "target_counts = df2[target_columns].sum(axis=1)\n",
        "is_multiple_targets = target_counts > 1\n",
        "is_other_flagged = df2['other'] == 1\n",
        "is_gaywom = df2['gaywom'] == 1\n",
        "is_blawom = df2['blawom'] == 1\n",
        "is_asiwom = df2['asiwom'] == 1\n",
        "is_muswom = df2['muswom'] == 1\n",
        "is_indigwom = df2['indigwom'] == 1\n",
        "is_mixed = df2['mixed'] == 1\n",
        "df2['is_intersectional'] = (is_multiple_targets | is_other_flagged | is_gaywom | is_blawom | is_asiwom | is_muswom | is_indigwom | is_mixed).astype(int)\n",
        "\n",
        "intersectional_count = (df2['is_intersectional'] == 1).sum()\n",
        "print(f\"Number of intersectional rows: {intersectional_count}\")\n",
        "\n",
        "merged_df = pd.merge(df1, df2, on='id', how='inner')\n",
        "merged_df = merged_df.dropna(subset=['text', 'is_intersectional'])\n",
        "merged_df.to_csv('processed_data.csv', index=False)\n",
        "\n",
        "texts = merged_df['text'].astype(str)\n",
        "labels = merged_df['is_intersectional'].astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeh-i9oWZ59M",
        "outputId": "ca9e6ea8-f6b9-4e96-c721-c705118f4d32"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-5b61b5b48d3e>:8: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df2 = pd.read_csv('hate_speech_data/2020-12-31-DynamicallyGeneratedHateDataset-targets-v0.1.csv')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of intersectional rows: 1993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read processed data into a pandas dataframe\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"processed_data.csv\")\n",
        "print(df.head())\n",
        "print(df['is_intersectional'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjKAYcAjQtmw",
        "outputId": "6b204dc2-8fa7-48a1-9771-d719726f538f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0     id                                               text label  \\\n",
            "0           1  10000  It should be legal for a husband to rape his wife  hate   \n",
            "1           2  10001                            dalits are lowlife scum  hate   \n",
            "2           3  10002                                dalits are lowlives  hate   \n",
            "3           4  10003  It was a better world when women dare not ques...  hate   \n",
            "4           5  10004  I don't work this hard so that those immigrant...  hate   \n",
            "\n",
            "       type model_wrong  db.model_preds           status round  split  ...  \\\n",
            "0  notgiven        True         0.97457  dynabench entry     1  train  ...   \n",
            "1  notgiven       False         0.08233  dynabench entry     1   test  ...   \n",
            "2  notgiven        True         0.92319  dynabench entry     1  train  ...   \n",
            "3  notgiven        True         0.99006  dynabench entry     1   test  ...   \n",
            "4  notgiven        True         0.98836  dynabench entry     1  train  ...   \n",
            "\n",
            "  eastern european  working  african  russian  indigwom  old  hitler  \\\n",
            "0                0        0        0        0         0    0       0   \n",
            "1                0        0        0        0         0    0       0   \n",
            "2                0        0        0        0         0    0       0   \n",
            "3                0        0        0        0         0    0       0   \n",
            "4                0        0        0        0         0    0       0   \n",
            "\n",
            "   NoTargetRecorded  other  is_intersectional  \n",
            "0                 1      0                  0  \n",
            "1                 1      0                  0  \n",
            "2                 1      0                  0  \n",
            "3                 1      0                  0  \n",
            "4                 1      0                  0  \n",
            "\n",
            "[5 rows x 55 columns]\n",
            "is_intersectional\n",
            "0    38630\n",
            "1     1993\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rename and encode labels, split dataframe into train/test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = df.rename(columns={'is_intersectional': 'labels', 'text': 'text'})\n",
        "\n",
        "label_map = {label: idx for idx, label in enumerate(df['labels'].unique())}\n",
        "df['labels'] = df['labels'].map(label_map)\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(df['text'].tolist(), df['labels'].tolist(), test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "qI2-777DRqKF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=128)\n"
      ],
      "metadata": {
        "id": "LU3XKRA7RvE9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "040f398aead74cc2947da8ccf1cea6c2",
            "1279530fbdbf44d684c84040584c5c38",
            "90059922178849c6bf771732f466fadb",
            "697f8c2c93fb4463a124aa7cc5a4268f",
            "079a69a117c24b7c9355d83a8629b369",
            "6960bbd7b9674871b848d02927d9f406",
            "21a61ed8d365414195466f2aaa92b00e",
            "c192e424b06548bd95355c3f0496008f",
            "d72f34f5fc02429d864ba8809cdab728",
            "3f7709b22b2f4b39a2d6ee10571e28e2",
            "fa809ae814d1470ebd95b9d7b862fc6c",
            "861da16c0d4241c8be0bab06e1f4f986",
            "6178d116ae65475f801d04ae8dd5600b",
            "3a45d7380cf243e7a25d5eabfbb38365",
            "15a35b7fa38e467f9815c2ad54b3cf68",
            "feaafb437c8645c8bc8a68441157cd8c",
            "18e4e26a0da4489fbbc0bf4b9d11ce27",
            "209c2d42549b4cd1a42580a2c1bde851",
            "e7d646bdee7f4a96a849f75933ce8eef",
            "cf2ef547705b430299f9f5e75031f0b5",
            "76fa4caefe4849e7a9862096782b4fec",
            "163a1bc6d9a545b3bfedfceae147931a",
            "d723cc4b107a47628c1f628cf33c7536",
            "dd08a056bb2b4579b07e187fbe9c1180",
            "6983ede666874dd284d2611d6dc12f03",
            "34257e3eebac48dbbbdda200e87606d5",
            "7576f2cd995b46a2b6b0796e2b66314d",
            "a30293cacd734ad4bd55445b3b7fe56b",
            "024f1b1bc580490c94913ca8e5c56cac",
            "7615058d9f844002817a8d2ff79ba3cd",
            "f5cfde5e247543468415fd7cec2090a2",
            "d44cd68b0a4245079cfa5494e460cf2b",
            "47e2f754611c457486454c41e5c54f41"
          ]
        },
        "outputId": "a122adcd-1cbc-4086-fa19-8d16bddcd5e8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "040f398aead74cc2947da8ccf1cea6c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "861da16c0d4241c8be0bab06e1f4f986"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d723cc4b107a47628c1f628cf33c7536"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert to dataset\n",
        "import torch\n",
        "\n",
        "class HateSpeechDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = HateSpeechDataset(train_encodings, train_labels)\n",
        "val_dataset = HateSpeechDataset(val_encodings, val_labels)\n"
      ],
      "metadata": {
        "id": "0IvyxbuRR67n"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load pretrained BERT model and set up training args\n",
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_map))\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=0,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"no\",\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67m1B3f6R-6V",
        "outputId": "fa80d406-1bf4-4313-9d91-355da07cef95"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train BERT classifier!\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\" # disable WANDB\n",
        "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "LRC_jGr_SaBz",
        "outputId": "278c4ce2-1c88-45a1-dd57-ae8b57cb6c6b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4063' max='4063' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4063/4063 07:53, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.094100</td>\n",
              "      <td>0.147921</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4063, training_loss=0.17073573838115297, metrics={'train_runtime': 473.8249, 'train_samples_per_second': 68.587, 'train_steps_per_second': 8.575, 'total_flos': 2137645769272320.0, 'train_loss': 0.17073573838115297, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate results using trainer evaluation function\n",
        "eval_results = trainer.evaluate()\n",
        "print(eval_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "0hDvvqs6XRNm",
        "outputId": "af15a4af-ea18-4b5c-b509-f95672191ff3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='127' max='127' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [127/127 00:27]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.1479213684797287, 'eval_runtime': 27.7704, 'eval_samples_per_second': 292.578, 'eval_steps_per_second': 4.573, 'epoch': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get more eval metrics\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import torch\n",
        "\n",
        "model.eval()\n",
        "\n",
        "preds = []\n",
        "labels = []\n",
        "\n",
        "for batch in torch.utils.data.DataLoader(val_dataset, batch_size=32):\n",
        "    batch = {k: v.to(model.device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "    preds.extend(predictions.cpu().numpy())\n",
        "    labels.extend(batch['labels'].cpu().numpy())\n",
        "\n",
        "accuracy = accuracy_score(labels, preds)\n",
        "precision = precision_score(labels, preds, average='weighted', zero_division=0)\n",
        "recall = recall_score(labels, preds, average='weighted', zero_division=0)\n",
        "f1 = f1_score(labels, preds, average='weighted', zero_division=0)\n",
        "\n",
        "print(f\"Validation Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Validation Precision: {precision:.4f}\")\n",
        "print(f\"Validation Recall:    {recall:.4f}\")\n",
        "print(f\"Validation F1 Score:  {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRELlYJ3YuTR",
        "outputId": "10753ef1-83db-4672-fb25-665c83602501"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy:  0.9536\n",
            "Validation Precision: 0.9399\n",
            "Validation Recall:    0.9536\n",
            "Validation F1 Score:  0.9418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code below this is to evaluate single samples for sanity testing and proof-of-concept examples**"
      ],
      "metadata": {
        "id": "bSlq16ikYn5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Example input list\n",
        "texts = [\n",
        "    \"I hate Black women\",             # Intersectional\n",
        "    \"I hate Indigenous women\",        # Intersectional\n",
        "    \"I hate Jewish women\",            # Intersectional\n",
        "    \"I hate Asian women\",             # Intersectional\n",
        "    \"I hate Muslim women\",            # Intersectional\n",
        "    \"Black women are terrible\",       # Intersectional\n",
        "    \"Indigenous women are terrible\",  # Intersectional\n",
        "    \"Jewish women are terrible\",      # Intersectional\n",
        "    \"Asian women are terrible\",       # Intersectional\n",
        "    \"Muslim women are terrible\",      # Intersectional\n",
        "    \"I hate white women\",             # NOT Intersectional\n",
        "    \"I hate Black men\",               # NOT Intersectional\n",
        "    \"I hate white men\",               # NOT Intersectional\n",
        "    \"I hate Indigenous men\",          # NOT Intersectional\n",
        "    \"I hate Jewish men\",              # NOT Intersectional\n",
        "    \"I hate Asian men\",               # NOT Intersectional\n",
        "    \"I hate Muslim men\",              # NOT Intersectional\n",
        "    \"White women are terrible\",       # NOT Intersectional\n",
        "    \"Black men are terrible\",         # NOT Intersectional\n",
        "    \"White men are terrible\",         # NOT Intersectional\n",
        "    \"Indigenous men are terrible\",    # NOT Intersectional\n",
        "    \"Jewish men are terrible\",        # NOT Intersectional\n",
        "    \"Asian men are terrible\",         # NOT Intersectional\n",
        "    \"Muslim men are terrible\",        # NOT Intersectional\n",
        "\n",
        "]\n",
        "\n",
        "encodings = tokenizer(texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=64)\n",
        "encodings = {k: v.to(model.device) for k, v in encodings.items()}\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(**encodings)\n",
        "    logits = outputs.logits\n",
        "    predicted_class_ids = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "\n",
        "inv_label_map = {v: k for k, v in label_map.items()}\n",
        "predicted_labels = [inv_label_map[i] for i in predicted_class_ids]\n",
        "\n",
        "for text, label in zip(texts, predicted_labels):\n",
        "    print(f\"'{text}': Predicted label: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nasuu5kbXpo2",
        "outputId": "6fe4a231-3837-4e05-d8a6-1c0586683646"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'I hate Black women': Predicted label: 1\n",
            "'I hate Indigenous women': Predicted label: 1\n",
            "'I hate Jewish women': Predicted label: 0\n",
            "'I hate Asian women': Predicted label: 0\n",
            "'I hate Muslim women': Predicted label: 0\n",
            "'Black women are terrible': Predicted label: 1\n",
            "'Indigenous women are terrible': Predicted label: 1\n",
            "'Jewish women are terrible': Predicted label: 0\n",
            "'Asian women are terrible': Predicted label: 0\n",
            "'Muslim women are terrible': Predicted label: 0\n",
            "'I hate white women': Predicted label: 0\n",
            "'I hate Black men': Predicted label: 0\n",
            "'I hate white men': Predicted label: 0\n",
            "'I hate Indigenous men': Predicted label: 0\n",
            "'I hate Jewish men': Predicted label: 0\n",
            "'I hate Asian men': Predicted label: 0\n",
            "'I hate Muslim men': Predicted label: 0\n",
            "'White women are terrible': Predicted label: 0\n",
            "'Black men are terrible': Predicted label: 0\n",
            "'White men are terrible': Predicted label: 0\n",
            "'Indigenous men are terrible': Predicted label: 0\n",
            "'Jewish men are terrible': Predicted label: 0\n",
            "'Asian men are terrible': Predicted label: 0\n",
            "'Muslim men are terrible': Predicted label: 0\n"
          ]
        }
      ]
    }
  ]
}
